{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bkw3_pB0s1L-"
   },
   "source": [
    "___\n",
    "\n",
    "<p style=\"text-align: center;\"><img src=\"https://docs.google.com/uc?id=1lY0Uj5R04yMY3-ZppPWxqCr5pvBLYPnV\" class=\"img-fluid\" \n",
    "alt=\"CLRSWY\"></p>\n",
    "\n",
    "## <p style=\"background-color:#FDFEFE; font-family:newtimeroman; color:#9d4f8c; font-size:100%; text-align:center; border-radius:10px 10px;\">WAY TO REINVENT YOURSELF</p>\n",
    "\n",
    "## <p style=\"background-color:#FDFEFE; font-family:newtimeroman; color:#060108; font-size:200%; text-align:center; border-radius:10px 10px;\">DA & DVwPY</p>\n",
    "\n",
    "## <p style=\"background-color:#FDFEFE; font-family:newtimeroman; color:#060108; font-size:200%; text-align:center; border-radius:10px 10px;\">The Exploratory Data Analysis (EDA) Project</p>\n",
    "\n",
    "<img src=https://i.ibb.co/wJW61Y2/Used-cars.jpg width=\"700\" height=\"200\">\n",
    "\n",
    "## <p style=\"background-color:#FDFEFE; font-family:newtimeroman; color:#060108; font-size:200%; text-align:center; border-radius:10px 10px;\">AutoScout Car Price Prediction EDA</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_oWczxZs1MA"
   },
   "source": [
    "## Introduction\n",
    "Welcome to \"***AutoScout Exploratory Data Analysis (EDA) Project***\". This is the project of completing ***Data Analysis & Data Visualization*** Courses and a successful hand-over is mandatory for getting certification for both courses. **Auto Scout** data used in this project scraped from the Website of an online car trading company in 2022, and contains many features of 13 different car makes including 594 models. In this project, you will have the opportunity to apply many commonly used algorithms for Data Cleaning and Exploratory Data Analysis by using a variety of Python libraries, such as Numpy, Pandas, Matplotlib, Seaborn, Scipy, and then you will get a clean dataset for your analysis and pretictive modelling in Machine Learning Path. So you will have the chance to use all the skills you have already learned in the Data Analysis and Visualization courses.\n",
    "\n",
    "**``In this context, the project consists of 3 parts in general:``**\n",
    "* **The first part** is related to ``'Data Cleaning'``. It deals with Incorrect Headers, Incorrect Format, Anomalies, and Dropping useless columns.\n",
    "* **The second part** is related to ``'Filling Data'``, in other words 'Imputation'. It deals with Missing Values. Categorical to numeric transformation, Encoding, is done as well.\n",
    "* **The third part** is related to ``'Handling Outliers of Data'`` via Visualization libraries. So, some insights will be extracted.\n",
    "\n",
    "**``SPECIAL NOTE:``**  However, you are ``free to create your own style``. You do ``NOT`` have to stick to the steps above. Nevertheless, we, the DA & DV instructors, recommend you study each part separately to create a source notebook for your further studies. \n",
    "\n",
    "In order to build your Portfolio in terms of the GitHub account, you need to push your solution file up to your own repository.\n",
    "\n",
    "Please after solving the task, commit your notebook to GitHub and submit its link to LMS page where the project is settled down.\n",
    "\n",
    "**BE NOTED:** Please ``DO NOT FORGET`` to click the submit button.\n",
    "\n",
    "### Some Reminders on Exploratory data analysis (EDA)\n",
    "\n",
    "Exploratory data analysis (EDA) is an especially important activity in the routine of a data analyst or scientist. It enables an in depth understanding of the dataset, define or discard hypotheses and create predictive models on a solid basis. It uses data manipulation techniques and several statistical tools to describe and understand the relationship between variables and how these can impact business. By means of EDA, we can obtain meaningful insights that can impact analysis under the following questions (If a checklist is good enough for pilots to use every flight, it’s good enough for data scientists to use with every dataset).\n",
    "1. What question are you trying to solve (or prove wrong)?\n",
    "2. What kind of data do you have?\n",
    "3. What’s missing from the data?\n",
    "4. Where are the outliers?\n",
    "5. How can you add, change or remove features to get more out of your data?\n",
    "\n",
    "**``Exploratory data analysis (EDA)``** is often an **iterative brainstorming process** where you pose a question, review the data, and develop further questions to investigate before beginning model development work. The image below shows how the brainstorming phase is connected with that of understanding the variables and how this in turn is connected again with the brainstorming phase.<br>\n",
    "\n",
    "<img src=https://i.ibb.co/k0MC950/EDA-Process.png width=\"300\" height=\"100\">\n",
    "\n",
    "[Image Credit: Andrew D.](https://towardsdatascience.com/exploratory-data-analysis-in-python-a-step-by-step-process-d0dfa6bf94ee)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvgJ5KWTs1MB"
   },
   "source": [
    "# PART- 1 `( Data Cleaning )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y13_gId7s1MC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGeKSdYds1MD"
   },
   "source": [
    "# PART- 2 `( Handling With Missing Vales )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDZnqBhbs1ME"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPPdPAu5s1ME"
   },
   "source": [
    "# PART- 3 `( Handling With Outliers )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Is4HLjHWs1MF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKxmsgfts1MG"
   },
   "source": [
    "# Final Step (Checking final situation of data via graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mgL_Bd0s1MG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PgUVPoes1MH"
   },
   "source": [
    "## Export dataframe to csv file (without dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Byg_o2ZMs1MI"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"final_scout_not_dummy.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrw9hr-3s1MJ"
   },
   "source": [
    "# Dummy Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faDyWTC9s1MJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUOdihlqs1MJ"
   },
   "source": [
    "## Export dataframe to csv file (dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJT7Yl1Us1MK"
   },
   "outputs": [],
   "source": [
    "df_dummied.to_csv(\"final_scout_dummy.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DAwPy-Capstone_Project_(AutoScout)_Student.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
